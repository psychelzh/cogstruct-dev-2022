---
title: "Prepare Tasks for Cognitive Training Project"
author: ["Liang Zhang", "Yifei Cao"]
date: "2022-06-08"
draft: false
format: 
  html:
    code-fold: true
    toc: true
execute: 
  warning: false
---

```{r}
library(tidyverse)
library(corrr)
library(formattable)
requireNamespace("bit64")
```

```{r}
pivot_wider_indices <- function(data, always_suffix = FALSE) {
  data |>
    add_count(user_id, game_name) |>
    mutate(
      game_index = if (always_suffix) {
        str_c(game_name, index_name, sep = "-")
      } else {
        if_else(
          n == 1,
          game_name,
          str_c(game_name, index_name, sep = "-")
        )
      }
    ) |>
    pivot_wider(
      id_cols = user_id,
      names_from = game_index,
      values_from = test
    )
}
format_dt <- function(x) {
  x |> 
    mutate(across(c(r, abs_r, icc), ~ digits(., 2))) |> 
    formattable(
      list(
        abs_r = formatter(
          "span",
          style = ~ style(
            color =
              case_when(
                abs_r > quantile(abs_r, 0.75) ~ "red",
                abs_r > quantile(abs_r, 0.25) ~ "blue",
                TRUE ~ "green"
              )
          )
        ),
        icc = color_tile("transparent", "pink")
      )
    ) |> 
    as.datatable(rownames = FALSE)
}
```

```{r}
targets::tar_load(
  reliability_test_retest, 
  store = here::here("preproc/_targets")
)
ind_filt <- readxl::read_excel(here::here("config/indices_filtering.xlsx"))
indices_clean <- targets::tar_read(
  indices_clean, 
  store = here::here("preproc/_targets")
) |>
  inner_join(
    filter(ind_filt, check_result == "target") |> 
      select(game_name, index_name, reversed) |> 
      add_row(
        game_name = "瑞文高级推理", 
        index_name = "nc_test",
        reversed = FALSE
      ),
    by = c("game_name", "index_name")
  ) |> 
  mutate(test = if_else(reversed, -test, test)) |> 
  group_by(game_name, index_name) |> 
  filter(!test %in% boxplot.stats(test)$out) |> 
  ungroup()
```

A basic principle choosing tasks for measuring training transfer effect is based on the correlations between the chosen tasks and the target tasks. Two types of target tasks are now selected:

-   Reasoning tasks: currently only two, namely, Raven's Advanced Progressive Matrices (RAPM) and Non-verbal Reasoning Task.
-   Visuo-spatial working memory tasks.

Here the correlations with these two types of tasks are calculated as follows.

# Correlation with Reasoning tasks

## RAPM

```{r}
indices_clean |> 
  filter(game_name_abbr != "RAPM") |> 
  inner_join(
    indices_clean |> 
      filter(
        game_name_abbr == "RAPM", 
        index_name == "nc_test"
      ) |> 
      select(user_id, rapm = test),
    by = "user_id"
  ) |> 
  group_by(game_name, index_name) |> 
  summarise(
    n = sum(!is.na(test) & !is.na(rapm)),
    r = cor(test, rapm, use = "complete"),
    .groups = "drop"
  ) |> 
  mutate(abs_r = abs(r)) |> 
  arrange(desc(abs_r)) |> 
  left_join(
    reliability_test_retest |> 
      select(game_name, index_name, icc = icc_no_outlier),
    by = c("game_name", "index_name")
  ) |> 
  format_dt()
```

## Nonverbal Reasoning

```{r}
indices_clean |> 
  filter(game_name_abbr != "NVR") |> 
  inner_join(
    indices_clean |> 
      filter(game_name_abbr == "NVR") |> 
      select(user_id, nvr = test),
    by = "user_id"
  ) |> 
  group_by(game_name, index_name) |> 
  summarise(
    n = sum(!is.na(test) & !is.na(nvr)),
    r = cor(test, nvr, use = "complete"),
    .groups = "drop"
  ) |> 
  filter(n > 100) |> 
  mutate(abs_r = abs(r)) |> 
  arrange(desc(abs_r)) |> 
  left_join(
    reliability_test_retest |> 
      select(game_name, index_name, icc = icc_no_outlier),
    by = c("game_name", "index_name")
  ) |> 
  format_dt()
```

## Average of these two tasks

```{r}
mean_scores <- indices_clean |> 
  filter(
    game_name_abbr == "NVR" |
      (game_name_abbr == "RAPM" & index_name == "nc_test")
  ) |> 
  pivot_wider(
    id_cols = user_id,
    names_from = game_name_abbr,
    values_from = test
  ) |> 
  mutate(
    across(c(NVR, RAPM), ~ scale(.)[, 1]),
    score_avg = map2_dbl(NVR, RAPM, ~ (.x + .y) / 2)
  )
indices_clean |> 
  filter(!game_name_abbr %in% c("NVR", "RAPM")) |> 
  inner_join(mean_scores, by = "user_id") |> 
  group_by(game_name, index_name) |> 
  summarise(
    n = sum(!is.na(test) & !is.na(score_avg)),
    r = cor(test, score_avg, use = "complete"),
    .groups = "drop"
  ) |> 
  filter(n > 100) |> 
  mutate(abs_r = abs(r)) |> 
  arrange(desc(abs_r)) |> 
  left_join(
    reliability_test_retest |> 
      select(game_name, index_name, icc = icc_no_outlier),
    by = c("game_name", "index_name")
  ) |> 
  format_dt()
```

# Correlation with Visual-Spatial Working Memory Tasks

```{r}
#| label: calc-latent-score
indices_viswm <- indices_clean |> 
  semi_join(
    ind_filt |> 
      filter(
        dimension %in% c("complex span", "working memory", "short term memory"),
        check_result == "target"
      ),
    by = c("game_name", "index_name")
  ) |> 
  pivot_wider_indices()
```

## The Latent Factor Model (hierarchical model)

```{r}
fitted <- lavaan::cfa(
  'Common =~ Updating + VerbalSTM + SpatialSTM
  Updating =~ `美术卡片` + `数字卡片` + `格子卡片` + `文字卡片`
  VerbalSTM =~ `幸运小球` + `密码箱` + `顺背数PRO`
  SpatialSTM =~ `宇宙黑洞` + `打靶场` + `蝴蝶照相机` + `位置记忆PRO`',
  indices_viswm, std.lv = TRUE, std.ov = TRUE,
  estimator = "MLR", missing = "ml"
)
semPlot::semPaths(
  fitted, what = "std", edge.color = "black", layout = "tree2",
  sizeMan = 6, sizeLat = 8, edge.label.cex = 0.6, intercepts = FALSE,
  nCharEdges = 5, esize = 1, trans = 1, nCharNodes = 0,
  bifactor = "Common"
)
lavaan::summary(fitted, fit.measures = TRUE, estimates = FALSE)
```

## Common Factor

```{r}
scores_latent <- bind_cols(
  select(indices_viswm, user_id),
  lavaan::predict(fitted) |> 
    unclass() |> 
    as_tibble()
)
indices_clean |> 
  inner_join(
    scores_latent,
    by = "user_id"
  ) |> 
  group_by(game_name, index_name) |> 
  summarise(
    n = sum(!is.na(test) & !is.na(Common)),
    r = cor(test, Common, use = "complete"),
    .groups = "drop"
  ) |> 
  mutate(abs_r = abs(r)) |> 
  arrange(desc(abs_r)) |> 
  left_join(
    reliability_test_retest |> 
      select(game_name, index_name, icc = icc_no_outlier),
    by = c("game_name", "index_name")
  ) |> 
  format_dt()
```

# Cognition Network

Another task is to find the core tasks for the cognition. A direct method is to find the task that has the largest sum of correlations with all other tasks. It is so-called strength of nodes in network.

## Strength for each task node

```{r}
#| fig-width: 10
#| fig-height: 6
library(tidygraph)
graph <- indices_clean |> 
  pivot_wider_indices() |> 
  select(-user_id) |> 
  correlate() |> 
  stretch(na.rm = TRUE, remove.dups = TRUE) |> 
  filter(r > 0.15) |> 
  tidygraph::as_tbl_graph(directed = FALSE)
strengths <- graph |> 
  activate(nodes) |> 
  mutate(strength = centrality_degree(weights = r)) |> 
  as_tibble() |> 
  arrange(desc(strength))
strengths |> 
  mutate(strength = digits(strength, 1)) |> 
  formattable(
    list(strength = color_text("green", "red"))
  ) |> 
  as.datatable()
strengths |> 
  ggplot(aes(fct_reorder(name, strength, .desc = TRUE), strength)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = "Task Name", y = "Strength (Weighted Degree)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Additional Analysis

```{r}
cog_data <- indices_clean |> 
  pivot_wider_indices(always_suffix = TRUE) |> 
  select(-user_id)
```

## Clustering tasks

Try to cluster tasks into three clusters, and select tasks from the clusters.

```{r}
suppressPackageStartupMessages(library(dendextend))
clust <- cog_data |> 
  cor(use = "pairwise") |> 
  smacof::sim2diss(to.dist = TRUE) |> 
  hclust()
# dend <- as.dendrogram(clust)
dend_k <- find_k(clust)
plot(dend_k)
dend <- clust |> 
  color_branches(k = dend_k$nc) |> 
  set("labels_cex", 0.4)
plot(dend)
rect.dendrogram(dend, k = dend_k$nc, border = 8)
```

## Factor Analysis

使用探索性因素分析的思路对于任务选取进行量化的定义。对于控制组、训练组的训练任务，以及近迁移、远迁移测试任务，我们的思路是：（1）训练组任务应与近迁移任务、远迁移任务拥有共同成分（Domain-general），而控制组训练任务与迁移任务没有共同成分；（2）训练组任务应与近迁移任务在Bi-factor模型中拥有共同的任务特殊性成分（Domain-specific）；（3）训练组任务应与远迁移任务在Bi-factor模型中处于不同的任务特殊性成分中。

### Step 1: finding general factor

在第一步中，我们对认知测试包含的所有任务具有代表性的指标进行探索性因素分析，并将factor数设置为1，意味着我们筛选出具有至少1个共同成分的任务作为训练组和迁移任务的备选。无法找出共同成分的任务，我们设置为控制组训练任务（factor的载荷低于0.4）。

```{r}
fit <- psych::fa(cog_data)
g_loadings <- fit$loadings |> 
  unclass() |> 
  as_tibble(rownames = "game_index")
```

基于此规则，我们得到不与其他任务具有共同general成分的任务如下。这些任务可以用作控制组训练任务。因为这些任务与其他任务并不能找到共同的general factor，如果符合预期，那么控制组的训练并不会对其他任务产生影响。

```{r}
g_loadings |> 
  filter(abs(MR1) < 0.4) |> 
  mutate(MR1 = digits(MR1, 2)) |> 
  formattable() |> 
  as.datatable(
    options = list(pageLength = 15)
  )
```

### Step 2: Bifactor model for domain-specific

下面，将筛选出的具有共同成分的任务使用Bi-factor模型，寻找domain-specific的因子。

```{r}
g_indices <- g_loadings |> 
  filter(abs(MR1) > 0.4) |> 
  pull(game_index)
cog_data_g <- cog_data |> 
  select(all_of(g_indices))
factor_test <- psych::nfactors(cog_data_g)
```

检验5个specific因子的模型：

-   **Correlated factor model**

```{r}
#| fig-width: 8
#| fig-height: 12
fit_fa <- psych::fa(cog_data_g, 4)
psych::fa.diagram(fit_fa)
```

-   **Bi-factor model**

```{r}
#| fig-width: 8
#| fig-height: 12
fit_bifac <- psych::omega(cog_data_g, 4, plot = FALSE)
psych::omega.diagram(fit_bifac)
```

按照我们的思路，训练组的训练任务可从bi-factor模型中的specific因子包含的任务中选取，近迁移任务可以选择为同一specific因子内部的任务，而远迁移任务可以选定为属于不同specific因子的任务。这样选定的原理是：（1）近迁移任务与训练任务既有domain-general factor的共享，也有domain-specific因子的共享；（2）而远迁移任务与训练任务只存在domain-general因子的重叠，而使用不同的domain-specific因子。*其中部分任务会出现共载荷现象，将不选择这些任务。*

# Analysis for candidate tasks

Selected tasks:

-   Control training tasks:
    -   舒尔特方格（中级）
    -   方向临摹
    -   一心二用PRO
    -   连点成画PRO
    -   超级秒表PRO
-   Experimental training tasks
    -   密码箱
    -   幸运小球
    -   打靶场
    -   蝴蝶照相机
-   Near Transfer
    -   顺背数PRO
    -   倒背数PRO
-   Far Transfer
    -   文字卡片
    -   美术卡片
    -   图形推理
    -   数字推理

```{r}
candidates <- readxl::read_excel("candidates.xlsx")
indices_selected <- indices_clean |> 
  semi_join(candidates, by = "game_name") |> 
  pivot_wider_indices(always_suffix = TRUE) |> 
  select(-user_id)
```

## Correlation Matrix

```{r}
#| fig-width: 10
#| fig-height: 8
correlate(indices_selected, quiet = TRUE) |> 
  rearrange(method = "HC") |>
  stretch() |> 
  mutate(across(c(x, y), as_factor)) |>
  ggplot(aes(x, y)) +
  geom_tile(aes(fill = r)) +
  scico::scale_fill_scico(palette = "bam", midpoint = 0, direction = -1) +
  coord_fixed() +
  theme_minimal(base_size = 18) +
  labs(x = "", y = "", fill = "Pearson's", color = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Multidimensional Scaling

```{r}
mds <- indices_selected |> 
  cor(use = "pairwise") |> 
  smacof::sim2diss(to.dist = TRUE) |> 
  smacof::mds(ndim = 2, type = "mspline")
plot(mds)
```

## Exploratory Factor Analysis

### Traditional

```{r}
nfactors_test <- psych::nfactors(indices_selected)
```

-   Correlated latent factors

```{r}
fit <- psych::fa(indices_selected, 3)
psych::fa.diagram(fit)
```

-   Bifactor model

```{r}
fit_bifac <- psych::omega(indices_selected, 3, plot = FALSE)
psych::omega.diagram(fit_bifac)
```
